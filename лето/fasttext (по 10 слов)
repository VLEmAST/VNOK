import fasttext
import fasttext.util
import numpy as np
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px  # –î–æ–±–∞–≤–ª—è–µ–º —ç—Ç–æ—Ç –∏–º–ø–æ—Ä—Ç
from sklearn.manifold import TSNE
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.preprocessing import StandardScaler

# –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏
print("üîÑ –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ FastText...")
ft_model = fasttext.load_model('cc.ru.300.bin')
print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")

def get_nearest_words(target_word, top_n=10):
    """–ü–æ–ª—É—á–∞–µ—Ç top_n —Å–∞–º—ã—Ö –±–ª–∏–∑–∫–∏—Ö —Å–ª–æ–≤ –∫ —Ü–µ–ª–µ–≤–æ–º—É —Å–ª–æ–≤—É"""
    try:
        # –ü–æ–ª—É—á–∞–µ–º –≤–µ–∫—Ç–æ—Ä —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞
        target_vector = ft_model.get_word_vector(target_word)
        target_vector = target_vector.reshape(1, -1)
        
        # –ü–æ–ª—É—á–∞–µ–º –±–ª–∏–∂–∞–π—à–∏–µ —Å–ª–æ–≤–∞
        nearest_words = ft_model.get_nearest_neighbors(target_word, k=top_n)
        
        return nearest_words, target_vector
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ª–æ–≤–∞ '{target_word}': {e}")
        return None, None

def visualize_nearest_words():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏"""
    
    print("\n" + "="*60)
    print("üéØ –í–ò–ó–£–ê–õ–ò–ó–ê–¶–ò–Ø –ë–õ–ò–ñ–ê–ô–®–ò–• –°–õ–û–í")
    print("="*60)
    
    # –ó–∞–ø—Ä–æ—Å —Å–ª–æ–≤ —É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    user_input = input("–í–≤–µ–¥–∏—Ç–µ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é: ").strip()
    
    if not user_input:
        print("‚ùå –ù–µ –≤–≤–µ–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–ª–æ–≤–∞!")
        return
    
    words_to_process = [word.strip() for word in user_input.split(',') if word.strip()]
    
    if not words_to_process:
        print("‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ valid–Ω—ã—Ö —Å–ª–æ–≤!")
        return
    
    print(f"\nüîç –ü–æ–∏—Å–∫ –±–ª–∏–∂–∞–π—à–∏—Ö —Å–ª–æ–≤ –¥–ª—è: {', '.join(words_to_process)}")
    
    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —Å–ª–æ–≤–∞ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏
    all_words_data = []
    target_words_info = {}
    
    for target_word in words_to_process:
        print(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–æ–≤–∞: '{target_word}'...")
        
        nearest_words, target_vector = get_nearest_words(target_word, top_n=10)
        
        if nearest_words is None:
            continue
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ü–µ–ª–µ–≤–æ–µ —Å–ª–æ–≤–æ
        all_words_data.append({
            'word': target_word,
            'vector': target_vector.flatten(),
            'is_target': True,
            'target_group': target_word,
            'similarity': 1.0
        })
        
        # –î–æ–±–∞–≤–ª—è–µ–º –±–ª–∏–∂–∞–π—à–∏–µ —Å–ª–æ–≤–∞
        for similarity, neighbor_word in nearest_words:
            all_words_data.append({
                'word': neighbor_word,
                'vector': ft_model.get_word_vector(neighbor_word),
                'is_target': False,
                'target_group': target_word,
                'similarity': similarity
            })
        
        target_words_info[target_word] = {
            'count': len(nearest_words) + 1,
            'neighbors': [word for _, word in nearest_words]
        }
    
    if not all_words_data:
        print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –Ω–∏ –æ–¥–Ω–æ —Å–ª–æ–≤–æ!")
        return
    
    # –°–æ–∑–¥–∞–µ–º DataFrame
    df = pd.DataFrame(all_words_data)
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤–µ–∫—Ç–æ—Ä—ã –≤ –º–∞—Å—Å–∏–≤
    X = np.array(df['vector'].tolist())
    words_list = df['word'].tolist()
    
    print(f"üìä –í—Å–µ–≥–æ —Å–ª–æ–≤ –¥–ª—è –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏: {len(df)}")
    
    # –ü—Ä–∏–º–µ–Ω—è–µ–º T-SNE
    print("üé® –°–æ–∑–¥–∞–Ω–∏–µ 3D –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏–∏...")
    
    # –ú–∞—Å—à—Ç–∞–±–∏—Ä—É–µ–º –¥–∞–Ω–Ω—ã–µ
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º perplexity –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å–ª–æ–≤
    n_samples = len(df)
    perplexity = min(5, max(2, n_samples // 10))
    
    tsne = TSNE(
        n_components=3,
        perplexity=perplexity,
        random_state=42,
        n_iter=1000,
        learning_rate=200
    )
    
    X_tsne = tsne.fit_transform(X_scaled)
    
    # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã –≤ DataFrame
    df['x'] = X_tsne[:, 0]
    df['y'] = X_tsne[:, 1]
    df['z'] = X_tsne[:, 2]
    
    # –°–æ–∑–¥–∞–µ–º –∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—É—é –≤–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—é
    fig = go.Figure()
    
    # –¶–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ü–µ–ª–µ–≤—ã—Ö —Å–ª–æ–≤ (–∏—Å–ø–æ–ª—å–∑—É–µ–º –ø–∞–ª–∏—Ç—Ä—É –∏–∑ plotly express)
    colors = px.colors.qualitative.Bold
    color_map = {}
    
    for i, target_word in enumerate(target_words_info.keys()):
        color_map[target_word] = colors[i % len(colors)]
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ—á–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ü–µ–ª–µ–≤–æ–≥–æ —Å–ª–æ–≤–∞ –∏ –µ–≥–æ —Å–æ—Å–µ–¥–µ–π
    for target_word in target_words_info.keys():
        group_df = df[df['target_group'] == target_word]
        
        # –¶–µ–ª–µ–≤–æ–µ —Å–ª–æ–≤–æ (–±–æ–ª—å—à–∞—è —Ç–æ—á–∫–∞)
        target_df = group_df[group_df['is_target'] == True]
        if not target_df.empty:
            fig.add_trace(go.Scatter3d(
                x=target_df['x'],
                y=target_df['y'],
                z=target_df['z'],
                mode='markers+text',
                marker=dict(
                    size=15,
                    color=color_map[target_word],
                    symbol='diamond',
                    line=dict(width=3, color='white')
                ),
                text=target_df['word'],
                textposition="middle center",
                textfont=dict(size=16, color='white', family="Arial Black"),
                name=f"üéØ {target_word} (—Ü–µ–ª–µ–≤–æ–µ)",
                hovertemplate=
                '<b>–¶–µ–ª–µ–≤–æ–µ —Å–ª–æ–≤–æ: %{text}</b><br>' +
                '<extra></extra>'
            ))
        
        # –ë–ª–∏–∂–∞–π—à–∏–µ —Å–ª–æ–≤–∞
        neighbors_df = group_df[group_df['is_target'] == False]
        if not neighbors_df.empty:
            fig.add_trace(go.Scatter3d(
                x=neighbors_df['x'],
                y=neighbors_df['y'],
                z=neighbors_df['z'],
                mode='markers+text',
                marker=dict(
                    size=8,
                    color=color_map[target_word],
                    opacity=0.8,
                    line=dict(width=1, color='white')
                ),
                text=neighbors_df['word'],
                textposition="middle center",
                textfont=dict(size=10, color='black'),
                name=f"üìå {target_word} (—Å–æ—Å–µ–¥–∏)",
                hovertemplate=
                '<b>%{text}</b><br>' +
                '–ë–ª–∏–∑–æ—Å—Ç—å –∫ "' + target_word + '": %{customdata:.3f}<br>' +
                '<extra></extra>',
                customdata=neighbors_df['similarity']
            ))
    
    # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º layout
    fig.update_layout(
        title=dict(
            text=f'<b>3D –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –±–ª–∏–∂–∞–π—à–∏—Ö —Å–ª–æ–≤<br>'
                 f'–¶–µ–ª–µ–≤—ã–µ —Å–ª–æ–≤–∞: {", ".join(target_words_info.keys())}</b>',
            font=dict(size=20, family='Arial'),
            x=0.5,
            xanchor='center'
        ),
        scene=dict(
            xaxis_title='X –∏–∑–º–µ—Ä–µ–Ω–∏–µ T-SNE',
            yaxis_title='Y –∏–∑–º–µ—Ä–µ–Ω–∏–µ T-SNE',
            zaxis_title='Z –∏–∑–º–µ—Ä–µ–Ω–∏–µ T-SNE',
            camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))
        ),
        width=1200,
        height=800,
        legend=dict(
            title=dict(text='<b>–ì—Ä—É–ø–ø—ã —Å–ª–æ–≤</b>'),
            x=0.02,
            y=0.98,
            bgcolor='rgba(255, 255, 255, 0.9)'
        )
    )
    
    # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
    filename = "nearest_words_visualization.html"
    fig.write_html(filename)
    print(f"üíæ –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {filename}")
    
    # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    print(f"\nüìä –°–¢–ê–¢–ò–°–¢–ò–ö–ê:")
    print(f"–í—Å–µ–≥–æ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ —Å–ª–æ–≤: {len(df)}")
    print(f"–¶–µ–ª–µ–≤—ã—Ö —Å–ª–æ–≤: {len(target_words_info)}")
    
    for target_word, info in target_words_info.items():
        print(f"\nüéØ '{target_word}':")
        print(f"   –ë–ª–∏–∂–∞–π—à–∏–µ —Å–ª–æ–≤–∞: {', '.join(info['neighbors'])}")
    
    fig.show()

# –û—Å–Ω–æ–≤–Ω–æ–π —Ü–∏–∫–ª
while True:
    visualize_nearest_words()
    
    print("\n" + "="*60)
    continue_input = input("–•–æ—Ç–∏—Ç–µ –≤–∏–∑—É–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –µ—â–µ —Å–ª–æ–≤–∞? (y/n): ").strip().lower()
    if continue_input not in ['y', 'yes', '–¥', '–¥–∞']:
        print("üëã –î–æ —Å–≤–∏–¥–∞–Ω–∏—è!")
        break
